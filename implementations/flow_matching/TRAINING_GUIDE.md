# Flow Matching è®­ç»ƒæµç¨‹å­¦ä¹ æŒ‡å—

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µå›é¡¾

### Flow Matching çš„è®­ç»ƒç›®æ ‡
è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œ `v_Î¸(x, t)` æ¥é¢„æµ‹é€Ÿåº¦åœºï¼Œä½¿å¾—ï¼š
- ä»å™ªå£° `x_0 ~ N(0, I)` å‡ºå‘
- é€šè¿‡æ±‚è§£ ODE: `dx/dt = v_Î¸(x, t)`
- æœ€ç»ˆåˆ°è¾¾æ•°æ®åˆ†å¸ƒ `x_1 ~ p_data`

### æŸå¤±å‡½æ•°
```
L = E_{t, x_0, x_1} [ ||v_Î¸(x_t, t) - (x_1 - x_0)||Â² ]
```

å…¶ä¸­ï¼š
- `x_t = (1-t) * x_0 + t * x_1` (çº¿æ€§æ’å€¼)
- `x_1 - x_0` æ˜¯çœŸå®çš„é€Ÿåº¦åœºï¼ˆOT Flow çš„å¸¸æ•°é€Ÿåº¦ï¼‰

---

## ğŸ“ ä»£ç ç»“æ„è¯¦è§£

### 1. æ•°æ®å¤„ç†æµç¨‹

```python
# Dataset è¿”å›çš„æ•°æ®æ ¼å¼
batch = {
    'trajectory': torch.Tensor,  # shape: (B, 6, 2)
    'type': list                 # ['circle', 'line', ...]
}

# è®­ç»ƒæ—¶çš„å¤„ç†æ­¥éª¤
x_1 = batch['trajectory']        # (B, 6, 2) - çœŸå®è½¨è¿¹
x_1 = x_1.reshape(B, -1)         # (B, 12) - Flatten
x_0 = torch.randn_like(x_1) * 0.5 # (B, 12) - é‡‡æ ·å™ªå£°
```

**ä¸ºä»€ä¹ˆè¦ Flattenï¼Ÿ**
- åŸå§‹æ•°æ®ï¼š6ä¸ªç‚¹ï¼Œæ¯ä¸ªç‚¹2ç»´ â†’ (6, 2)
- ç½‘ç»œè¾“å…¥ï¼šéœ€è¦ä¸€ä¸ªå‘é‡ â†’ (12,)
- è¿™æ ·ç½‘ç»œå¯ä»¥å­¦ä¹ æ•´æ¡è½¨è¿¹çš„é€Ÿåº¦åœº

**ä¸ºä»€ä¹ˆ x_0 ç”¨ randnï¼Ÿ**
- Flow Matching ä»å™ªå£°åˆ†å¸ƒå¼€å§‹
- `randn` é‡‡æ ·æ ‡å‡†æ­£æ€åˆ†å¸ƒ N(0, 1)
- ä¹˜ä»¥ 0.5 æ˜¯ä¸ºäº†å‡å°åˆå§‹å™ªå£°çš„æ–¹å·®

---

### 2. è®­ç»ƒå¾ªç¯ (train_epoch)

```python
def train_epoch(self, epoch: int) -> float:
    self.model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼ˆå¯ç”¨ dropout ç­‰ï¼‰
    
    for batch in self.train_loader:
        # Step 1: å‡†å¤‡æ•°æ®
        x_1 = batch['trajectory'].to(device)  # ç§»åˆ° GPU
        x_1 = x_1.reshape(B, -1)              # Flatten
        x_0 = torch.randn_like(x_1) * 0.5     # é‡‡æ ·å™ªå£°
        
        # Step 2: æ¸…é›¶æ¢¯åº¦ï¼ˆé‡è¦ï¼ï¼‰
        self.optimizer.zero_grad()
        
        # Step 3: è®¡ç®—æŸå¤±
        loss = self.flow_matcher.compute_cfm_loss(model, x_0, x_1)
        
        # Step 4: åå‘ä¼ æ’­
        loss.backward()
        
        # Step 5: æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        # Step 6: æ›´æ–°å‚æ•°
        self.optimizer.step()
    
    return avg_loss
```

**å…³é”®ç‚¹**ï¼š
1. **zero_grad()**: å¿…é¡»æ¸…é›¶ï¼Œå¦åˆ™æ¢¯åº¦ä¼šç´¯ç§¯
2. **backward()**: è®¡ç®—æ¢¯åº¦
3. **step()**: æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°
4. **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š

---

### 3. éªŒè¯å¾ªç¯ (validate)

```python
def validate(self) -> float:
    self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ dropoutï¼‰
    
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
        for batch in self.val_loader:
            # åªè®¡ç®—æŸå¤±ï¼Œä¸æ›´æ–°å‚æ•°
            loss = self.flow_matcher.compute_cfm_loss(model, x_0, x_1)
    
    return avg_loss
```

**ä¸è®­ç»ƒçš„åŒºåˆ«**ï¼š
- âŒ ä¸è°ƒç”¨ `zero_grad()`
- âŒ ä¸è°ƒç”¨ `backward()`
- âŒ ä¸è°ƒç”¨ `step()`
- âœ… ä½¿ç”¨ `torch.no_grad()` èŠ‚çœå†…å­˜

---

### 4. å®Œæ•´è®­ç»ƒæµç¨‹ (train)

```python
def train(self, num_epochs: int):
    for epoch in range(num_epochs):
        # 1. è®­ç»ƒä¸€ä¸ª epoch
        train_loss = self.train_epoch(epoch)
        
        # 2. éªŒè¯
        val_loss = self.validate()
        
        # 3. ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.save_checkpoint(epoch, val_loss, is_best=True)
```

---

## ğŸ”§ ä½ çš„ä»£ç é—®é¢˜æ€»ç»“

### âŒ é—®é¢˜ 1: æ•°æ®å¤„ç†é”™è¯¯
```python
# ä½ çš„ä»£ç 
batch_x1s = batch  # batch æ˜¯å­—å…¸
batch_x0s = torch.rand_like(batch_x1s)  # âŒ ä¸èƒ½å¯¹å­—å…¸ç”¨ rand_like
```

**æ­£ç¡®åšæ³•**ï¼š
```python
x_1 = batch['trajectory'].to(device)  # æå– trajectory
x_1 = x_1.reshape(batch_size, -1)     # Flatten
x_0 = torch.randn_like(x_1) * 0.5     # é‡‡æ ·å™ªå£°
```

---

### âŒ é—®é¢˜ 2: éªŒè¯æ—¶æ›´æ–°äº†å‚æ•°
```python
# ä½ çš„ä»£ç ï¼ˆåœ¨ validate å‡½æ•°ä¸­ï¼‰
self.optimizer.zero_grad()  # âŒ éªŒè¯æ—¶ä¸éœ€è¦
loss.backward()             # âŒ éªŒè¯æ—¶ä¸éœ€è¦
self.optimizer.step()       # âŒ éªŒè¯æ—¶ä¸éœ€è¦
```

**æ­£ç¡®åšæ³•**ï¼š
```python
with torch.no_grad():
    loss = self.flow_matcher.compute_cfm_loss(model, x_0, x_1)
    # åªè®¡ç®—æŸå¤±ï¼Œä¸æ›´æ–°å‚æ•°
```

---

### âŒ é—®é¢˜ 3: æ¨¡å‹æ¥å£ä¸åŒ¹é…
ä½ çš„ `VelocityFieldMLP` éœ€è¦ 3 ä¸ªå‚æ•°ï¼š
```python
def forward(self, state, cond, t):  # éœ€è¦ condition
```

ä½† toy dataset ä¸éœ€è¦æ¡ä»¶ï¼Œæ‰€ä»¥æˆ‘åˆ›å»ºäº† `SimpleVelocityField`ï¼š
```python
def forward(self, x, t):  # åªéœ€è¦ state å’Œ time
```

---

## ğŸš€ å¦‚ä½•è¿è¡Œè®­ç»ƒ

### 1. ç”Ÿæˆæ•°æ®é›†ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
```bash
cd implementations/flow_matching/data
python toy_dataset.py
```

### 2. å¼€å§‹è®­ç»ƒ
```bash
cd implementations/flow_matching
python train.py --epochs 50 --batch_size 32 --lr 1e-3
```

### 3. æŸ¥çœ‹è®­ç»ƒè¿›åº¦
è®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºï¼š
```
Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:10<00:00, loss=0.234567]
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, loss=0.123456]

Epoch 1/50
  Train Loss: 0.234567
  Val Loss:   0.123456
  âœ“ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±!
```

---

## ğŸ“Š è®­ç»ƒæŠ€å·§

### 1. å­¦ä¹ ç‡è°ƒæ•´
```python
# ä½¿ç”¨ä½™å¼¦é€€ç«
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=epochs, eta_min=1e-6
)
```

### 2. æ¢¯åº¦è£å‰ª
```python
# é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### 3. æ—©åœ (Early Stopping)
å¦‚æœéªŒè¯æŸå¤±ä¸å†ä¸‹é™ï¼Œå¯ä»¥æå‰åœæ­¢è®­ç»ƒã€‚

### 4. ä¿å­˜æ£€æŸ¥ç‚¹
```python
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'val_loss': val_loss,
}
torch.save(checkpoint, 'best.pth')
```

---

## ğŸ“ å­¦ä¹ å»ºè®®

### ç¬¬ä¸€æ¬¡å†™è®­ç»ƒä»£ç çš„å¸¸è§å›°æƒ‘

1. **ä¸ºä»€ä¹ˆè¦ zero_grad()ï¼Ÿ**
   - PyTorch é»˜è®¤ä¼šç´¯ç§¯æ¢¯åº¦
   - æ¯æ¬¡åå‘ä¼ æ’­å‰å¿…é¡»æ¸…é›¶

2. **backward() å’Œ step() çš„åŒºåˆ«ï¼Ÿ**
   - `backward()`: è®¡ç®—æ¢¯åº¦ï¼ˆå­˜å‚¨åœ¨ `.grad` ä¸­ï¼‰
   - `step()`: æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°

3. **train() å’Œ eval() çš„åŒºåˆ«ï¼Ÿ**
   - `train()`: å¯ç”¨ dropoutã€batch norm ç­‰
   - `eval()`: å…³é—­ dropoutã€batch norm ç­‰

4. **ä¸ºä»€ä¹ˆéªŒè¯æ—¶ç”¨ no_grad()ï¼Ÿ**
   - ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
   - åŠ å¿«è®¡ç®—é€Ÿåº¦

---

## ğŸ“– æ¨èå­¦ä¹ èµ„æº

1. **PyTorch å®˜æ–¹æ•™ç¨‹**
   - Training a Classifier: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html

2. **ç†è§£åå‘ä¼ æ’­**
   - 3Blue1Brown çš„è§†é¢‘ç³»åˆ—

3. **è°ƒè¯•æŠ€å·§**
   - æ‰“å°å¼ é‡å½¢çŠ¶ï¼š`print(x.shape)`
   - æ£€æŸ¥æ¢¯åº¦ï¼š`print(model.parameters()[0].grad)`
   - ä½¿ç”¨ `pdb` è°ƒè¯•å™¨

---

## âœ… ä¸‹ä¸€æ­¥

å®Œæˆè®­ç»ƒåï¼Œä½ éœ€è¦ï¼š
1. âœ… è¿è¡Œè®­ç»ƒè„šæœ¬
2. âœ… è§‚å¯ŸæŸå¤±æ›²çº¿
3. âœ… ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆè½¨è¿¹
4. âœ… å¯è§†åŒ–ç»“æœï¼ˆæˆ‘æ¥å¸®ä½ å®Œæˆï¼‰

åŠ æ²¹ï¼ğŸš€
