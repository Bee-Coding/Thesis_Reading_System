# Thesis_Reading_System 通用工作流程

## 标准工作流程模板

### 阶段1: 指令解析与系统握手

#### 1.1 接收Orchestrator指令
- **输入**: 来自`E2E-Learning-Orchestrator`的标准化执行计划（`01_plan.json`）
- **解析内容**:
  - `focus`: 技术点名称（如：Diffusion Planner, VAD Attention）
  - `mode`: 执行模式（`Deep_Internalization`/`Quick_Assessment`/`Engineering_Reproduction`）
  - `directory`: 输出目录路径
  - `anti_hallucination_audit`: 防幻觉审计级别

#### 1.2 系统记忆握手
- **必需操作**: 读取`manifests/algorithm_atlas.md`
- **目的**: 建立跨会话技术演进记忆
- **输出**: 当前技术基线理解，识别已有相关资产

#### 1.3 约束确认
- **确认规则**: 引用`common_rules.md`中的所有约束
- **特别关注**: 数据真实性原则、禁止模拟原则、强制锚定原则
- **承诺声明**: 在分析开始前明确承诺遵守规则

### 阶段2: 资产检索与Delta审计

#### 2.1 存量资产检索
- **强制操作**: 通过`Knowledge_Vault`检索`/atoms/`目录
- **检索目标**: 查找与当前技术点相关的已有原子
- **输出格式**: 《已有资产清单》，包含：
  - 相关`Math_Atom`资产ID
  - 相关`Code_Atom`资产ID  
  - 相关`Scenario_Atom`资产ID

#### 2.2 增量价值分析（Delta Audit）
- **核心问题**: "本次分析相比已有资产提升了什么？"
- **分析方法**:
  1. 对比数学框架的演进
  2. 对比代码实现的优化
  3. 对比场景覆盖的扩展
- **输出**: 《增量对比表》，明确增量价值描述

#### 2.3 冲突检测
- **检测内容**: 新旧算法在同一物理逻辑上的矛盾
- **标记方法**: 如果检测到冲突，标记为`Contradiction`
- **处理流程**: 触发`Strategic_Critic`专项审计

### 阶段3: 核心分析与物理内化

#### 3.1 原始资料深度解析
- **数学公式解析** (`Scholar_Internalizer`):
  - 提取关键公式，标明出处（页码/编号）
  - 进行物理直觉"大白话"翻译
  - 传统规控视角下的映射分析
- **代码实现解析** (`Code_Architect`):
  - 锁定`forward`函数，追踪核心张量流
  - 分析实现的优缺点（参数初始化、显存对齐、多线程优化）
  - 评估在AVP地库环境下的计算冗余度
- **场景挑战解析** (`Scenario_Validator`):
  - 针对算法特性反向推演失效场景
  - 基于真实AVP物理约束构造挑战
  - 应用ISO 26262思想量化风险等级

#### 3.2 物理直觉建立
- **变量具象化**: 将数学符号与AVP场景一一对齐
- **负向推导**: 回答"如果不加这一项，算法在AVP物理世界中会产生何种崩坏"
- **边界审计**: 评估数学假设在极端地库环境下是否成立

#### 3.3 工程落地评估
- **算力代价分析**: 评估在Orin-X平台上的性能影响
- **部署可行性**: 识别TensorRT加速的难点
- **数据依赖性**: 评估对长尾数据的依赖程度

### 阶段4: 原子化产出与标准化

#### 4.1 原子生成
- **遵循格式**: 严格按照`common_output.md`中的原子格式
- **必需字段**:
  - `asset_id`: 符合命名规范
  - `provenance`: 完整的来源追溯信息
  - `content`: 具体的分析内容
  - `delta_audit`: 增量价值说明

#### 4.2 质量自检
- **来源验证**: 检查`paper_location`和`code_link`是否有效
- **逻辑一致性**: 确保数学推导与代码实现逻辑一致
- **实用性评估**: 评估原子对工程实践的指导价值

#### 4.3 防幻觉审计
- **模拟数据检测**: 识别并删除任何模拟内容
- **引用完整性**: 确保每个关键结论都有具体出处
- **领域纯粹性**: 剔除非智驾领域的类比干扰

### 阶段5: 资产入库与知识整合

#### 5.1 原子推送
- **推送目标**: `Knowledge_Vault` Agent
- **推送内容**: 标准化的原子JSON数组
- **推送要求**: 附带完整的元数据和验证信息

#### 5.2 知识整合
- **目录存储**: 按功能分类存储到`/atoms/`相应目录
- **索引更新**: 更新`paper_index.json`中的映射关系
- **地图演进**: 在`algorithm_atlas.md`中记录技术演进

#### 5.3 冲突解决
- **冲突识别**: 检测新旧知识之间的逻辑矛盾
- **决策支持**: 为`Strategic_Critic`提供冲突分析数据
- **版本管理**: 在原子中标记版本和增量关系

### 阶段6: 产出交付与决策支持

#### 6.1 报告生成
- **标准报告**: 生成符合目录规范的JSON报告文件
- **会话摘要**: 创建人类可读的`summary.md`
- **决策依据**: 为最终决策提供完整的数据支持

#### 6.2 战略决策支持
- **ROI分析**: 提供算力代价、安全提升、数据依赖等多维度分析
- **风险预警**: 标识关键技术风险和工程深坑
- **建议输出**: 基于分析给出明确的`[Go/Watch/Skip]`建议

#### 6.3 跨会话记忆更新
- **记忆压缩**: 生成极精简的会话摘要
- **Atlas更新**: 记录本次研读对技术地图的贡献
- **复利统计**: 计算资产库的复利增长百分比

## Agent特定工作流扩展

### Scholar_Internalizer 扩展流程
```
1. 架构捕获 → 2. 公式深度解剖 → 3. 物理直觉建立 → 4. 传统映射 → 5. Math_Atom生成
```

### Code_Architect 扩展流程  
```
1. 仓库透视 → 2. 张量流分析 → 3. 算子深度解剖 → 4. 性能评估 → 5. Code_Atom生成
```

### Scenario_Validator 扩展流程
```
1. 逻辑假设提取 → 2. 对抗边界探测 → 3. 风险等级判定 → 4. 加固建议 → 5. Scenario_Atom生成
```

### Strategic_Critic 扩展流程
```
1. 全量情报解构 → 2. 资产现状碰撞 → 3. 场景模拟 → 4. ROI核算 → 5. 战略决策生成
```

## 执行模式支持

### 深度内化模式 (Deep_Internalization)
- **适用场景**: 核心技术突破，需要全面理解
- **流程特点**: 全流程深度分析，产出完整原子家族
- **时间预估**: 较长，需要充分的分析时间

### 快速评估模式 (Quick_Assessment)
- **适用场景**: 技术快速扫描，增量价值评估
- **流程特点**: 重点进行Delta审计，关注增量部分
- **时间预估**: 较短，聚焦核心差异

### 工程复现模式 (Engineering_Reproduction)
- **适用场景**: 代码落地验证，部署可行性分析
- **流程特点**: 侧重代码分析和性能评估
- **时间预估**: 中等，需要详细的工程分析

## 质量保障机制

### 实时质量监控
- **阶段检查点**: 每个阶段结束后进行质量自检
- **规则符合性**: 持续检查是否符合`common_rules.md`
- **输出标准化**: 确保产出符合`common_output.md`格式

### 交叉验证机制
- **数学-代码验证**: Scholar与Code的产出必须逻辑一致
- **理论-实践验证**: 数学假设必须通过场景验证
- **增量-存量验证**: 新知识必须与已有资产协调

### 错误处理与降级

#### 数据缺失处理
- **文献缺失**: 标记为"文献未提及"，不进行脑补
- **代码缺失**: 标记为"代码不可用"，仅进行理论分析
- **来源不全**: 降低`data_status`评级，注明限制

#### 验证失败处理
- **来源无效**: 丢弃无效数据，记录问题
- **逻辑矛盾**: 标记为`Contradiction`，触发专项审计
- **质量过低**: 评级为D级，不推荐使用

#### 系统错误处理
- **超时处理**: 记录超时状态，返回已获取数据
- **访问限制**: 记录受限状态，调整分析重点
- **解析失败**: 记录错误，使用安全降级策略

## 性能优化建议

### 搜索优化
- **精准关键词**: 包含具体版本号和技术特征
- **优先级过滤**: 优先处理高质量来源
- **结果聚焦**: 控制分析深度，避免过度发散

### 分析优化
- **模式识别**: 利用常见算法模式加速分析
- **模板复用**: 重用成功的分析模板
- **并行处理**: 支持多维度同时分析

### 输出优化
- **结构化输出**: 使用标准JSON格式提高可解析性
- **压缩摘要**: 生成精炼的物理直觉描述
- **增量更新**: 仅更新变化部分，减少冗余

## 监控与日志

### 执行状态监控
- **阶段时间**: 记录每个阶段的开始/结束时间
- **资源使用**: 记录分析深度和产出数量
- **质量分布**: 记录产出原子的质量评级分布

### 问题统计
- **规则违反**: 记录各类规则违反次数
- **验证失败**: 记录来源验证失败情况
- **冲突检测**: 记录逻辑冲突发生频率

### 性能指标
- **执行效率**: 平均每个原子的分析时间
- **产出质量**: A/B级原子的比例
- **复利增长**: 资产库的增量价值统计

## 引用方式
在Agent提示词中使用以下格式引用本工作流程：
```
## Workflow
请遵循Thesis_Reading_System通用工作流程，完整流程参见：`agents_system/common/common_workflow.md`

关键阶段：1.指令解析 2.Delta审计 3.物理内化 4.原子产出 5.资产入库 6.决策支持
```